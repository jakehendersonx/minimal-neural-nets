{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude 3.5 Sonnet Prompt\n",
    "Write a neural network in PyTorch that can add two numbers. \n",
    "Call it AddNet. \n",
    "It should add two whole numbers that are between 0 and 100.\n",
    "Goal 1 is to get it to add two arbitrary whole numbers in a defined range with the lowest possible error.Goal 2 is to keep the neural net and training definitions to be as simple as possible while still accomplishing Goal 1.\n",
    "At each relevant step of your network definition and training, write about why you made the choice to use that \"technique\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.159147\n",
      "Epoch [200/1000], Loss: 0.062354\n",
      "Epoch [300/1000], Loss: 0.028616\n",
      "Epoch [400/1000], Loss: 0.012465\n",
      "Epoch [500/1000], Loss: 0.008091\n",
      "Epoch [600/1000], Loss: 0.004660\n",
      "Epoch [700/1000], Loss: 0.003388\n",
      "Epoch [800/1000], Loss: 0.002730\n",
      "Epoch [900/1000], Loss: 0.002180\n",
      "Epoch [1000/1000], Loss: 0.001726\n",
      "\n",
      "Test Result:\n",
      "Numbers: 5.7 + 3.2\n",
      "Predicted sum: 8.9001\n",
      "Actual sum: 8.9000\n",
      "Error: 0.0001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class AddNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddNet, self).__init__()\n",
    "        # A simple architecture with two hidden layers\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(2, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Initialize the model\n",
    "model = AddNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Generate training data\n",
    "def generate_data(num_samples=1000):\n",
    "    # Generate random numbers between -10 and 10\n",
    "    x1 = np.random.uniform(-10, 10, (num_samples, 1))\n",
    "    x2 = np.random.uniform(-10, 10, (num_samples, 1))\n",
    "    # True sums\n",
    "    y = x1 + x2\n",
    "    # Convert to PyTorch tensors\n",
    "    X = torch.FloatTensor(np.hstack((x1, x2)))\n",
    "    y = torch.FloatTensor(y)\n",
    "    return X, y\n",
    "\n",
    "# Training loop\n",
    "def train(epochs=1000):\n",
    "    for epoch in range(epochs):\n",
    "        X, y = generate_data()\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}')\n",
    "\n",
    "# Train the model\n",
    "train()\n",
    "\n",
    "# Test the model\n",
    "def test_addition(x1, x2):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.FloatTensor([[x1, x2]])\n",
    "        prediction = model(input_tensor)\n",
    "        return prediction.item()\n",
    "\n",
    "# Example usage\n",
    "x1, x2 = 5.7, 3.2\n",
    "predicted_sum = test_addition(x1, x2)\n",
    "actual_sum = x1 + x2\n",
    "print(f\"\\nTest Result:\")\n",
    "print(f\"Numbers: {x1} + {x2}\")\n",
    "print(f\"Predicted sum: {predicted_sum:.4f}\")\n",
    "print(f\"Actual sum: {actual_sum:.4f}\")\n",
    "print(f\"Error: {abs(predicted_sum - actual_sum):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, num_samples=10):\n",
    "    \"\"\"\n",
    "    Evaluates the addition model on randomly generated number pairs.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained AddNet model\n",
    "        num_samples: Number of evaluation pairs to generate\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Generate evaluation data\n",
    "    x1 = np.random.uniform(-10, 10, (num_samples, 1))\n",
    "    x2 = np.random.uniform(-10, 10, (num_samples, 1))\n",
    "    \n",
    "    print(\"\\nModel Evaluation Results\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Number 1':<12} {'Number 2':<12} {'Predicted':<12} {'Actual':<12} {'Error':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    total_error = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            # Get the numbers for this sample\n",
    "            num1, num2 = x1[i][0], x2[i][0]\n",
    "            actual = num1 + num2\n",
    "            \n",
    "            # Make prediction\n",
    "            input_tensor = torch.FloatTensor([[num1, num2]])\n",
    "            predicted = model(input_tensor).item()\n",
    "            \n",
    "            # Calculate error\n",
    "            error = abs(predicted - actual)\n",
    "            total_error += error\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"{num1:<12.4f} {num2:<12.4f} {predicted:<12.4f} {actual:<12.4f} {error:<12.4f}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    avg_error = total_error / num_samples\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Average Error: {avg_error:.6f}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Example usage:\n",
    "# evaluate_model(model, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Results\n",
      "============================================================\n",
      "Number 1     Number 2     Predicted    Actual       Error       \n",
      "------------------------------------------------------------\n",
      "5.1053       2.9027       8.0081       8.0081       0.0000      \n",
      "3.1782       0.7628       3.9400       3.9410       0.0009      \n",
      "7.3105       -8.9348      -1.5934      -1.6243      0.0309      \n",
      "1.3971       -4.1529      -2.7763      -2.7558      0.0205      \n",
      "5.2125       -5.0050      0.2178       0.2074       0.0104      \n",
      "9.9177       -6.1530      3.7605       3.7647       0.0042      \n",
      "-6.9283      -8.6794      -15.5803     -15.6076     0.0273      \n",
      "-3.4678      4.7029       1.2032       1.2351       0.0318      \n",
      "-8.3155      -5.8125      -14.1283     -14.1280     0.0004      \n",
      "-2.3396      -9.8137      -12.1241     -12.1534     0.0293      \n",
      "------------------------------------------------------------\n",
      "Average Error: 0.015568\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 6.0963\n",
      "Epoch [200/1000], Loss: 1.1273\n",
      "Epoch [300/1000], Loss: 0.6245\n",
      "Epoch [400/1000], Loss: 0.4382\n",
      "Epoch [500/1000], Loss: 0.3222\n",
      "Epoch [600/1000], Loss: 0.2338\n",
      "Epoch [700/1000], Loss: 0.1663\n",
      "Epoch [800/1000], Loss: 0.1156\n",
      "Epoch [900/1000], Loss: 0.0783\n",
      "Epoch [1000/1000], Loss: 0.0517\n",
      "\n",
      "Test: 25.0 + 75.0 = 100.0003 (Actual: 100.0)\n"
     ]
    }
   ],
   "source": [
    "# The second attempt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class AddNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 16)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(16, 8)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(8, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation1(self.layer1(x))\n",
    "        x = self.activation2(self.layer2(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Generate training data\n",
    "def generate_data(num_samples=1000):\n",
    "    x1 = np.random.uniform(0, 100, (num_samples, 1))\n",
    "    x2 = np.random.uniform(0, 100, (num_samples, 1))\n",
    "    X = np.hstack((x1, x2))\n",
    "    y = x1 + x2\n",
    "    return torch.FloatTensor(X), torch.FloatTensor(y)\n",
    "\n",
    "# Training setup\n",
    "model = AddNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "X_train, y_train = generate_data()\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "test_x1, test_x2 = 25.0, 75.0\n",
    "test_input = torch.FloatTensor([[test_x1, test_x2]])\n",
    "predicted_sum = model(test_input)\n",
    "print(f'\\nTest: {test_x1} + {test_x2} = {predicted_sum.item():.4f} (Actual: {test_x1 + test_x2})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: 48.77769470214844 + 71.0080337524414 = 119.6938 (Actual: 119.78572845458984)\n",
      "\n",
      "Test: 49.3056526184082 + 1.2821018695831299 = 50.9178 (Actual: 50.58775329589844)\n",
      "\n",
      "Test: 73.80733489990234 + 51.15372085571289 = 124.9178 (Actual: 124.9610595703125)\n",
      "\n",
      "Test: 28.075145721435547 + 90.93944549560547 = 118.9499 (Actual: 119.01458740234375)\n",
      "\n",
      "Test: 32.875816345214844 + 50.911521911621094 = 83.8631 (Actual: 83.78733825683594)\n",
      "\n",
      "Test: 43.70690155029297 + 77.75537109375 = 121.3439 (Actual: 121.46227264404297)\n",
      "\n",
      "Test: 15.821111679077148 + 5.7428717613220215 = 21.9631 (Actual: 21.563983917236328)\n",
      "\n",
      "Test: 66.68196105957031 + 27.91709327697754 = 94.7174 (Actual: 94.59905242919922)\n",
      "\n",
      "Test: 72.29139709472656 + 34.02498245239258 = 106.3816 (Actual: 106.31637573242188)\n",
      "\n",
      "Test: 22.633207321166992 + 30.947362899780273 = 53.8070 (Actual: 53.580570220947266)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "samples = torch.rand((num_samples, 2)) * 100\n",
    "for i, row in enumerate(samples):\n",
    "    x1, x2 = row[0], row[1]\n",
    "    predicted_sum = model(row)\n",
    "    print(f'\\nTest: {x1} + {x2} = {predicted_sum.item():.4f} (Actual: {x1 + x2})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a neural network in PyTorch that can add two numbers. \n",
    "Call it AddNet. \n",
    "It should add two whole numbers that are between 0 and 100.\n",
    "Goal 1 is to get it to add two arbitrary whole numbers in a defined range with the lowest possible error.Goal 2 is to keep the neural net and training definitions to be as simple as possible while still accomplishing Goal 1.\n",
    "Describe why you choose the Network Architecture, Activation Function, Loss Function, Optimizer, Training Data, Amount of Training Data, and Training Process to accomplish this task specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and visualizing network architecture...\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/nocuments/code/projects/minimal-neural-nets/.venv/lib/python3.12/site-packages/graphviz/backend/execute.py:78\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:1955\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 130\u001b[0m\n\u001b[1;32m    127\u001b[0m     test_add_net(model, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 119\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating and visualizing network architecture...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m model \u001b[38;5;241m=\u001b[39m AddNet()\n\u001b[0;32m--> 119\u001b[0m \u001b[43mvisualize_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m, in \u001b[0;36mvisualize_network\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     23\u001b[0m y \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m     24\u001b[0m dot \u001b[38;5;241m=\u001b[39m make_dot(y, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m.\u001b[39mnamed_parameters()))\n\u001b[0;32m---> 25\u001b[0m \u001b[43mdot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maddnet_architecture\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcleanup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Print model details\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Structure:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/nocuments/code/projects/minimal-neural-nets/.venv/lib/python3.12/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nocuments/code/projects/minimal-neural-nets/.venv/lib/python3.12/site-packages/graphviz/rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[0;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[1;32m    118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n\u001b[0;32m--> 122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    125\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n",
      "File \u001b[0;32m~/nocuments/code/projects/minimal-neural-nets/.venv/lib/python3.12/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nocuments/code/projects/minimal-neural-nets/.venv/lib/python3.12/site-packages/graphviz/backend/rendering.py:326\u001b[0m, in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[1;32m    322\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork around pytype false alarm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 326\u001b[0m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mfspath(outfile)\n",
      "File \u001b[0;32m~/nocuments/code/projects/minimal-neural-nets/.venv/lib/python3.12/site-packages/graphviz/backend/execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchviz import make_dot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class AddNet(nn.Module):\n",
    "    \"\"\"Neural network designed to learn addition of two numbers between 0 and 100.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(AddNet, self).__init__()\n",
    "        self.hidden = nn.Linear(2, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(16, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "def visualize_network(model):\n",
    "    \"\"\"Creates and saves a visualization of the network architecture.\"\"\"\n",
    "    x = torch.randn(1, 2)\n",
    "    y = model(x)\n",
    "    dot = make_dot(y, params=dict(model.named_parameters()))\n",
    "    dot.render(\"addnet_architecture\", format=\"png\", cleanup=True)\n",
    "    \n",
    "    # Print model details\n",
    "    print(\"Model Structure:\")\n",
    "    print(model)\n",
    "    \n",
    "    print(\"\\nDetailed Layer Information:\")\n",
    "    for name, parameter in model.named_parameters():\n",
    "        print(f\"{name}: {parameter.size()}\")\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\nTotal trainable parameters: {total_params}\")\n",
    "\n",
    "def generate_training_data(num_samples):\n",
    "    \"\"\"Generates training data pairs and their sums.\"\"\"\n",
    "    x1 = torch.randint(0, 101, (num_samples, 1), dtype=torch.float32)\n",
    "    x2 = torch.randint(0, 101, (num_samples, 1), dtype=torch.float32)\n",
    "    inputs = torch.cat((x1, x2), dim=1)\n",
    "    targets = x1 + x2\n",
    "    return inputs, targets\n",
    "\n",
    "def train_add_net(model, num_epochs=1000, batch_size=64):\n",
    "    \"\"\"Trains the neural network using generated data.\"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Generate training data\n",
    "    inputs, targets = generate_training_data(10000)\n",
    "    \n",
    "    # Lists to store loss history\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Random batch selection\n",
    "        idx = torch.randperm(inputs.shape[0])[:batch_size]\n",
    "        batch_inputs = inputs[idx]\n",
    "        batch_targets = targets[idx]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Store loss\n",
    "        loss_history.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Plot loss history\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_history)\n",
    "    plt.title('Training Loss Over Time')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "def test_add_net(model, num_samples):\n",
    "    \"\"\"Tests the trained model and displays results.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Generate test data\n",
    "        x1 = torch.randint(0, 101, (num_samples, 1), dtype=torch.float32)\n",
    "        x2 = torch.randint(0, 101, (num_samples, 1), dtype=torch.float32)\n",
    "        inputs = torch.cat((x1, x2), dim=1)\n",
    "        actual_sums = x1 + x2\n",
    "        \n",
    "        # Get predictions\n",
    "        predicted_sums = model(inputs)\n",
    "        \n",
    "        # Calculate and display results\n",
    "        print(\"\\nTesting Results:\")\n",
    "        print(\"X1\\tX2\\tPredicted\\tActual\\t\\t%Error\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        total_error = 0\n",
    "        for i in range(num_samples):\n",
    "            error_pct = abs(predicted_sums[i].item() - actual_sums[i].item()) / actual_sums[i].item() * 100\n",
    "            total_error += error_pct\n",
    "            print(f\"{x1[i].item():.0f}\\t{x2[i].item():.0f}\\t{predicted_sums[i].item():.2f}\\t\\t{actual_sums[i].item():.2f}\\t\\t{error_pct:.2f}%\")\n",
    "        \n",
    "        print(f\"\\nAverage error: {total_error/num_samples:.2f}%\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the entire process.\"\"\"\n",
    "    # Create and visualize model\n",
    "    print(\"Creating and visualizing network architecture...\")\n",
    "    model = AddNet()\n",
    "    visualize_network(model)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nStarting training...\")\n",
    "    train_add_net(model)\n",
    "    \n",
    "    # Test model\n",
    "    print(\"\\nTesting model...\")\n",
    "    test_add_net(model, 10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
