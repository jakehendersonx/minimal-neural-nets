{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddNet, self).__init__()\n",
    "        # two inputs, one output\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4103, 0.2921],\n",
       "        [0.0812, 0.7048],\n",
       "        [0.6621, 0.2070],\n",
       "        [0.3180, 0.5248],\n",
       "        [0.9884, 0.7344]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_normalized_data(num_samples):\n",
    "    x = torch.rand((10, 2))\n",
    "    x_mean = x.mean(dim=0, keepdim=True)\n",
    "    x_std = x.std(dim=0, keepdim=True)\n",
    "    x_normalized = (x - x_mean) / x_std\n",
    "\n",
    "    y = x.sum(dim=1, keepdim=True)\n",
    "    y_normalized = (y - y.mean()) / y.std()\n",
    "    return x_normalized, y_normalized, x_mean, x_std, y.mean(), y.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, x_train_mean, x_train_std, y_train_mean, y_train_std, test_samples=10):\n",
    "    x_test = torch.rand((test_samples, 2)) * 100\n",
    "    y_actual = x_test.sum(dim=1, keepdim=True)\n",
    "    x_test_normalized = (x_test - x_train_mean) / x_train_std\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_normalized = model(x_test_normalized)\n",
    "        y_pred = y_pred_normalized * y_train_std + y_train_mean\n",
    "    \n",
    "    print(f\"{'Input':<25}{'Predicted':<15}{'Actual':<15}{'Error':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    for i in range(test_samples):\n",
    "        input_vals = f\"{x_test[i,0].item():.2f}, {x_test[i,1].item():.2f}\"\n",
    "        predicted = y_pred[i].item()\n",
    "        actual = y_actual[i].item()\n",
    "        error = abs(predicted - actual)\n",
    "        print(f\"{input_vals:<25}{predicted:<15.2f}{actual:<15.2f}{error:<10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AddNet()\n",
    "model.apply(init_weights)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_mean, x_std, y_mean, y_std = generate_normalized_data(30000)\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.5166\n",
      "Epoch 100, Loss: 1.3292\n",
      "Epoch 200, Loss: 1.1566\n",
      "Epoch 300, Loss: 0.9968\n",
      "Epoch 400, Loss: 0.8491\n",
      "Epoch 500, Loss: 0.7134\n",
      "Epoch 600, Loss: 0.5896\n",
      "Epoch 700, Loss: 0.4775\n",
      "Epoch 800, Loss: 0.3788\n",
      "Epoch 900, Loss: 0.2987\n",
      "Epoch 1000, Loss: 0.2341\n",
      "Epoch 1100, Loss: 0.1820\n",
      "Epoch 1200, Loss: 0.1401\n",
      "Epoch 1300, Loss: 0.1067\n",
      "Epoch 1400, Loss: 0.0802\n",
      "Epoch 1500, Loss: 0.0594\n",
      "Epoch 1600, Loss: 0.0433\n",
      "Epoch 1700, Loss: 0.0311\n",
      "Epoch 1800, Loss: 0.0219\n",
      "Epoch 1900, Loss: 0.0151\n",
      "Epoch 2000, Loss: 0.0103\n",
      "Epoch 2100, Loss: 0.0068\n",
      "Epoch 2200, Loss: 0.0044\n",
      "Epoch 2300, Loss: 0.0028\n",
      "Epoch 2400, Loss: 0.0017\n",
      "Epoch 2500, Loss: 0.0010\n",
      "Epoch 2600, Loss: 0.0006\n",
      "Epoch 2700, Loss: 0.0003\n",
      "Epoch 2800, Loss: 0.0002\n",
      "Epoch 2900, Loss: 0.0001\n",
      "Epoch 3000, Loss: 0.0000\n",
      "Epoch 3100, Loss: 0.0000\n",
      "Epoch 3200, Loss: 0.0000\n",
      "Epoch 3300, Loss: 0.0000\n",
      "Epoch 3400, Loss: 0.0000\n",
      "Epoch 3500, Loss: 0.0000\n",
      "Epoch 3600, Loss: 0.0000\n",
      "Epoch 3700, Loss: 0.0000\n",
      "Epoch 3800, Loss: 0.0000\n",
      "Epoch 3900, Loss: 0.0000\n",
      "Epoch 4000, Loss: 0.0000\n",
      "Epoch 4100, Loss: 0.0000\n",
      "Epoch 4200, Loss: 0.0000\n",
      "Epoch 4300, Loss: 0.0000\n",
      "Epoch 4400, Loss: 0.0000\n",
      "Epoch 4500, Loss: 0.0000\n",
      "Epoch 4600, Loss: 0.0000\n",
      "Epoch 4700, Loss: 0.0000\n",
      "Epoch 4800, Loss: 0.0000\n",
      "Epoch 4900, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # forward pass\n",
    "    predictions = model(x_train)\n",
    "    loss = criterion(predictions, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                    Predicted      Actual         Error     \n",
      "-----------------------------------------------------------------\n",
      "17.23, 48.11             65.33          65.34          0.01      \n",
      "15.28, 36.39             51.65          51.66          0.01      \n",
      "61.28, 66.13             127.39         127.41         0.02      \n",
      "68.16, 59.95             128.09         128.11         0.02      \n",
      "94.89, 27.54             122.42         122.44         0.02      \n",
      "72.41, 78.74             151.13         151.15         0.02      \n",
      "14.60, 93.18             107.77         107.78         0.02      \n",
      "30.31, 97.24             127.53         127.55         0.02      \n",
      "39.69, 73.55             113.22         113.23         0.02      \n",
      "65.87, 52.52             118.38         118.39         0.02      \n",
      "57.10, 91.77             148.86         148.88         0.02      \n",
      "46.64, 30.56             77.19          77.20          0.01      \n",
      "32.05, 53.16             85.20          85.21          0.01      \n",
      "19.88, 17.62             37.49          37.50          0.01      \n",
      "99.46, 21.77             121.22         121.23         0.02      \n",
      "9.31, 18.79              28.09          28.10          0.00      \n",
      "67.61, 93.52             161.11         161.14         0.02      \n",
      "25.13, 92.08             117.19         117.20         0.02      \n",
      "33.49, 75.07             108.55         108.56         0.02      \n",
      "86.42, 48.80             135.20         135.21         0.02      \n",
      "91.52, 59.58             151.08         151.11         0.02      \n",
      "9.10, 57.53              66.63          66.63          0.01      \n",
      "92.43, 43.31             135.73         135.74         0.02      \n",
      "5.18, 6.68               11.85          11.86          0.00      \n",
      "47.55, 83.53             131.06         131.08         0.02      \n",
      "37.53, 75.61             113.12         113.14         0.02      \n",
      "36.01, 60.98             96.97          96.99          0.01      \n",
      "52.06, 74.26             126.30         126.32         0.02      \n",
      "7.73, 13.19              20.92          20.93          0.00      \n",
      "75.59, 89.84             165.40         165.43         0.02      \n",
      "99.76, 38.32             138.06         138.08         0.02      \n",
      "86.68, 20.53             107.20         107.21         0.01      \n",
      "2.83, 81.95              84.76          84.78          0.01      \n",
      "81.66, 95.65             177.28         177.31         0.02      \n",
      "33.88, 88.95             122.81         122.83         0.02      \n",
      "80.15, 56.87             137.00         137.02         0.02      \n",
      "64.37, 57.04             121.38         121.40         0.02      \n",
      "24.32, 91.45             115.75         115.77         0.02      \n",
      "51.24, 36.83             88.06          88.07          0.01      \n",
      "7.79, 70.81              78.58          78.59          0.01      \n",
      "7.49, 37.72              45.20          45.21          0.01      \n",
      "80.22, 84.41             164.60         164.63         0.02      \n",
      "78.62, 59.79             138.39         138.41         0.02      \n",
      "79.49, 95.52             174.99         175.01         0.02      \n",
      "67.47, 63.48             130.93         130.95         0.02      \n",
      "76.76, 8.97              85.72          85.73          0.01      \n",
      "38.37, 0.82              39.19          39.19          0.01      \n",
      "3.68, 35.82              39.49          39.49          0.01      \n",
      "85.57, 75.09             160.64         160.66         0.02      \n",
      "70.72, 38.05             108.76         108.77         0.01      \n",
      "3.55, 9.43               12.98          12.98          0.00      \n",
      "49.46, 15.88             65.33          65.34          0.01      \n",
      "23.21, 71.79             94.99          95.01          0.01      \n",
      "40.10, 65.69             105.78         105.79         0.01      \n",
      "52.04, 75.96             127.98         128.00         0.02      \n",
      "61.27, 34.24             95.50          95.51          0.01      \n",
      "69.52, 72.40             141.89         141.91         0.02      \n",
      "82.29, 93.96             176.22         176.25         0.02      \n",
      "42.48, 24.86             67.33          67.34          0.01      \n",
      "64.50, 0.94              65.43          65.44          0.01      \n",
      "47.05, 43.01             90.04          90.06          0.01      \n",
      "75.98, 88.33             164.28         164.31         0.02      \n",
      "8.98, 81.11              90.08          90.09          0.01      \n",
      "30.83, 20.03             50.85          50.86          0.01      \n",
      "19.24, 43.23             62.46          62.47          0.01      \n",
      "97.18, 45.45             142.61         142.63         0.02      \n",
      "29.38, 73.45             102.82         102.83         0.01      \n",
      "9.52, 75.38              84.89          84.91          0.01      \n",
      "2.71, 82.64              85.34          85.35          0.01      \n",
      "51.93, 84.69             136.60         136.62         0.02      \n",
      "91.79, 7.75              99.53          99.54          0.01      \n",
      "49.24, 99.27             148.49         148.51         0.02      \n",
      "39.49, 63.62             103.10         103.12         0.01      \n",
      "61.42, 0.69              62.10          62.11          0.01      \n",
      "59.15, 90.40             149.53         149.55         0.02      \n",
      "35.04, 30.73             65.76          65.77          0.01      \n",
      "72.40, 37.69             110.08         110.09         0.01      \n",
      "52.58, 62.56             115.12         115.14         0.02      \n",
      "15.00, 1.31              16.31          16.31          0.00      \n",
      "98.36, 92.37             190.70         190.72         0.03      \n",
      "29.45, 98.99             128.42         128.44         0.02      \n",
      "61.65, 50.83             112.47         112.48         0.02      \n",
      "68.91, 38.64             107.53         107.55         0.01      \n",
      "3.76, 90.79              94.53          94.54          0.01      \n",
      "61.11, 70.37             131.46         131.48         0.02      \n",
      "66.04, 94.37             160.38         160.40         0.02      \n",
      "41.09, 17.88             58.96          58.97          0.01      \n",
      "42.91, 24.67             67.57          67.58          0.01      \n",
      "55.17, 50.02             105.18         105.19         0.01      \n",
      "58.11, 35.82             93.91          93.92          0.01      \n",
      "83.90, 33.29             117.17         117.19         0.02      \n",
      "1.62, 42.69              44.30          44.31          0.01      \n",
      "58.80, 44.58             103.37         103.38         0.01      \n",
      "17.60, 47.23             64.82          64.83          0.01      \n",
      "23.81, 35.16             58.97          58.97          0.01      \n",
      "73.24, 21.36             94.58          94.59          0.01      \n",
      "96.17, 23.09             119.25         119.27         0.02      \n",
      "93.15, 50.09             143.22         143.24         0.02      \n",
      "59.62, 99.35             158.95         158.97         0.02      \n",
      "64.95, 39.98             104.92         104.93         0.01      \n"
     ]
    }
   ],
   "source": [
    "eval(model, x_mean, x_std, y_mean, y_std, test_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
