{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.829310178756714\n",
      "Epoch 500, Loss: 1.9475975036621094\n",
      "Epoch 1000, Loss: 0.78922438621521\n",
      "Epoch 1500, Loss: 0.15770266950130463\n",
      "Epoch 2000, Loss: 0.016104672104120255\n",
      "Epoch 2500, Loss: 0.0008411712478846312\n",
      "Epoch 3000, Loss: 1.7257056242669933e-05\n",
      "Epoch 3500, Loss: 1.2401521587435127e-07\n",
      "Epoch 4000, Loss: 3.302814466366044e-09\n",
      "Epoch 4500, Loss: 2.6808528730271064e-09\n",
      "Input: tensor([[10., 20.],\n",
      "        [15., 25.]])\n",
      "Predicted Sum (Rounded): tensor([[21.],\n",
      "        [28.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network\n",
    "class AddNumbersNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddNumbersNet, self).__init__()\n",
    "        self.fc = nn.Linear(2, 1)  # Two inputs, one output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Proper weight initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)  # Xavier initialization for stability\n",
    "        nn.init.zeros_(m.bias)  # Initialize biases to zero\n",
    "\n",
    "# Generate normalized dataset\n",
    "def generate_data(num_samples=5000):  # Increased dataset size\n",
    "    x = torch.rand((num_samples, 2)) * 100  # Random numbers between 0 and 100\n",
    "    x = (x - x.mean()) / x.std()  # Standardize inputs to zero mean and unit variance\n",
    "    y = x.sum(dim=1, keepdim=True)  # Sum the two numbers\n",
    "    y = y / y.std()  # Normalize target to match input scale\n",
    "    return x, y\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = AddNumbersNet()\n",
    "model.apply(init_weights)  # Apply weight initialization\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Adam optimizer for better convergence\n",
    "\n",
    "# Training loop\n",
    "x_train, y_train = generate_data(5000)\n",
    "epochs = 5000  # Train for more epochs\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    predictions = model(x_train)\n",
    "    loss = criterion(predictions, y_train)\n",
    "\n",
    "    # Check for NaN loss\n",
    "    if torch.isnan(loss).any():\n",
    "        print(f\"Loss is NaN at epoch {epoch}!\")\n",
    "        break\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Gradient clipping to prevent exploding gradients\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log every 500 epochs\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Test the model\n",
    "x_test = torch.tensor([[10.0, 20.0], [15.0, 25.0]])\n",
    "x_test = (x_test - x_train.mean()) / x_train.std()  # Normalize test data\n",
    "y_test = model(x_test)\n",
    "y_test_rounded = y_test.round()  # Round predictions to nearest whole number\n",
    "print(\"Input:\", x_test)\n",
    "print(\"Predicted Sum (Rounded):\", y_test_rounded.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.0852, -1.4949],\n",
      "        [ 1.0021,  0.8382],\n",
      "        [-0.2320,  0.4840],\n",
      "        [-0.6381, -0.8283],\n",
      "        [-0.8017,  0.1593],\n",
      "        [-0.8495,  0.7828],\n",
      "        [-1.6055, -1.2282],\n",
      "        [ 1.5005, -0.8097],\n",
      "        [ 0.1867,  1.5583],\n",
      "        [ 1.2385,  0.8226]]), tensor([[-0.9613],\n",
      "        [ 1.1196],\n",
      "        [ 0.1533],\n",
      "        [-0.8922],\n",
      "        [-0.3908],\n",
      "        [-0.0406],\n",
      "        [-1.7240],\n",
      "        [ 0.4203],\n",
      "        [ 1.0617],\n",
      "        [ 1.2540]]))\n"
     ]
    }
   ],
   "source": [
    "data = generate_data(10)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.9498544931411743\n",
      "Epoch 500, Loss: 2.473349559295457e-05\n",
      "Epoch 1000, Loss: 1.3263051187095698e-05\n",
      "Epoch 1500, Loss: 9.237308404408395e-06\n",
      "Epoch 2000, Loss: 5.803426120110089e-06\n",
      "Epoch 2500, Loss: 3.690952780743828e-06\n",
      "Epoch 3000, Loss: 2.6776713184517575e-06\n",
      "Epoch 3500, Loss: 1.8784181747832918e-06\n",
      "Epoch 4000, Loss: 1.6382275589421624e-06\n",
      "Epoch 4500, Loss: 1.351693867945869e-06\n",
      "Input               Predicted           Actual              Error     \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to list.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 48\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_samples)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(test_samples):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m<20\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;01m{\u001b[39;00my_pred_rounded[i]\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<20.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00my_actual[i]\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<20.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(y_pred_rounded[i]\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39my_actual[i]\u001b[38;5;241m.\u001b[39mitem())\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to list.__format__"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network with additional layers\n",
    "class AddNumbersNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddNumbersNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)  # Input to hidden layer\n",
    "        self.fc2 = nn.Linear(64, 32)  # Hidden layer\n",
    "        self.fc3 = nn.Linear(32, 1)  # Hidden to output layer\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Proper weight initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)  # Xavier initialization for stability\n",
    "        nn.init.zeros_(m.bias)  # Initialize biases to zero\n",
    "\n",
    "# Generate normalized dataset\n",
    "def generate_data(num_samples=5000):  # Increased dataset size\n",
    "    x = torch.rand((num_samples, 2)) * 100  # Random numbers between 0 and 100\n",
    "    x = (x - x.mean()) / x.std()  # Standardize inputs to zero mean and unit variance\n",
    "    y = x.sum(dim=1, keepdim=True)  # Sum the two numbers\n",
    "    y = y / y.std()  # Normalize target to match input scale\n",
    "    return x, y\n",
    "\n",
    "# Test data generation and evaluation function\n",
    "def evaluate_model(model, test_samples=10):\n",
    "    x_test = torch.rand((test_samples, 2)) * 100  # Generate test data\n",
    "    y_actual = x_test.sum(dim=1, keepdim=True)  # Calculate actual sums\n",
    "    x_test_normalized = (x_test - x_train.mean()) / x_train.std()  # Normalize test data\n",
    "\n",
    "    # Get predictions and round for whole numbers\n",
    "    y_pred = model(x_test_normalized).detach()\n",
    "    y_pred_scaled = y_pred * y_train.std()  # Rescale predictions to original range\n",
    "    y_pred_rounded = y_pred_scaled.round()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"{'Input':<20}{'Predicted':<20}{'Actual':<20}{'Error':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    for i in range(test_samples):\n",
    "        input_vals = \", \".join(f\"{v:.2f}\" for v in x_test[i].tolist())  # Format list as a string\n",
    "        print(f\"{input_vals:<20}{y_pred_rounded[i].item():<20.2f}{y_actual[i].item():<20.2f}{abs(y_pred_rounded[i].item() - y_actual[i].item()):<10.2f}\")\n",
    "\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = AddNumbersNet()\n",
    "model.apply(init_weights)  # Apply weight initialization\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Adam optimizer for better convergence\n",
    "\n",
    "# Training loop\n",
    "x_train, y_train = generate_data(5000)\n",
    "epochs = 5000  # Train for more epochs\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    predictions = model(x_train)\n",
    "    loss = criterion(predictions, y_train)\n",
    "\n",
    "    # Check for NaN loss\n",
    "    if torch.isnan(loss).any():\n",
    "        print(f\"Loss is NaN at epoch {epoch}!\")\n",
    "        break\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Gradient clipping to prevent exploding gradients\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log every 500 epochs\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_samples=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
